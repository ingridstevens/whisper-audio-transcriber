{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncovering Insights in Audio \n",
    "\n",
    "We will use two approaches \n",
    "1. 'Trad' RAG aka Traditional Retreival Augmented Generation (complete with splitting, tokenizing, embedding, and using for similarity search)\n",
    "2. Prompt Stuffing (adding the entire transcript within the prompt and using the model to generate answers based on that)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Transcription\n",
    "\n",
    "Since both approaches require having a transcription, we'll go ahead and do that first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcribe the Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses Whisper API from OpenAI to generate audio from text\n",
    "import whisper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from whisper (i have chosen to use the medium model, as it is more accurate than the base model)\n",
    "model = whisper.load_model(\"medium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add your Audio File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = \"BryanThe_Ideal_Republic.ogg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transcribe the audio file**\n",
    "\n",
    "Note: this may take some time (about a minute)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I can conceive of a national destiny which meets the responsibilities of today and measures up to the possibilities of tomorrow. Behold a republic resting securely upon the mountain of eternal truth. A republic applying in practice and proclaiming to the world the self-evident propositions that all men are created equal, that they are endowed with inalienable rights, that governments are instituted among men to secure these rights, and that governments derive their just powers from the consent of the governed. Behold a republic in which civil and religious liberty stimulate all to earnest endeavor, and in which the law restrains every hand uplifted for a neighbor's injury. A republic in which every citizen is a sovereign, but in which no one cares to wear a crown. Behold a republic standing erect while empires all around or bow beneath the weight of their own armaments. A republic whose flag is love while other flags are only fears. Behold a republic increasing in population, in wealth, in strength, and in influence, solving the problems of civilization and facing the coming of a universal brotherhood. A republic which shakes, throes, and dissolves aristocracies by its silent example and gives light and inspiration to those who sit in darkness. Behold a republic gradually but surely becoming a supreme moral factor in the world's progress and the accepted arbiter of the world's dispute. A republic whose history, like the path of the just, is as the shining light that shineth more and more unto the perfect day.\n"
     ]
    }
   ],
   "source": [
    "# Run the transcription and save it to \"result\"\n",
    "# Note: the original audio file is available on Wikipedia at this link: https://commons.wikimedia.org/wiki/File:A_J_Cook_Speech_from_Lansbury%27s_Labour_Weekly.ogg \n",
    "result = model.transcribe(audio, fp16=False)\n",
    "\n",
    "# Print the transcription\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the Imports for the Entire Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: Audio to RAG \n",
    "**Retreival Augmented Generation over audio files transcribed with Whisper API**\n",
    "\n",
    "Now that we've transcribed the audio using the Whisper API, we can use the transcript to create a RAG prompt.\n",
    "\n",
    "This section of the notebook leads you step-by-step through the process of:\n",
    "* Tokenizing the text using the LangChain `RecursiveCharacterTextSplitter`\n",
    "* Creating embeddings from the tokenized text using `Ollama Embeddings`\n",
    "* Performing a similary search between query and vectorstore `docsearch.similarity_search`\n",
    "* Creating an LangChain LLMChain which takes in context, query, and returns the answer, considering the context and query together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: Split, Tokenize & Embed the text \n",
    "Tokenizing and Embeddings are created to split the transcription into smaller chunks and create embeddings for each chunk. This allows us to search for similar chunks in the vectorstore. This is a crucial step in RAG (retreival augmented generation), as it allows us to find the most similar chunks to the query, and then generate text based on the context of the query and the most similar chunks.\n",
    "\n",
    "We use langchain to split the text with the RecursiveCharacterTextSplitter, which splits the text into smaller chunks recursively. We then create embeddings for each chunk using Ollama Embeddings. You can swap these individual components out for whatever text splitter or embeddings you'd prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I can conceive of a national destiny which meets the responsibilities of today and measures up to the possibilities of tomorrow. Behold a republic resting securely upon the mountain of eternal truth. A republic applying in practice and proclaiming to the world the self-evident propositions that all men are created equal, that they are endowed with inalienable rights, that governments are instituted among men to secure these rights, and that governments derive their just powers from the consent of the governed. Behold a republic in which civil and religious liberty stimulate all to earnest endeavor, and in which the law restrains every hand uplifted for a neighbor's injury. A republic in which every citizen is a sovereign, but in which no one cares to wear a crown. Behold a republic standing erect while empires all around or bow beneath the weight of their own armaments. A republic whose flag is love while other flags are only fears. Behold a republic increasing in population, in wealth, in strength, and in influence, solving the problems of civilization and facing the coming of a universal brotherhood. A republic which shakes, throes, and dissolves aristocracies by its silent example and gives light and inspiration to those who sit in darkness. Behold a republic gradually but surely becoming a supreme moral factor in the world's progress and the accepted arbiter of the world's dispute. A republic whose history, like the path of the just, is as the shining light that shineth more and more unto the perfect day.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the text to split\n",
    "transcription = result[\"text\"]\n",
    "\n",
    "# Display the text\n",
    "transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the text**\n",
    "\n",
    "Here, the text is split into chunks of 100 characters, with overlaps of 20 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "\n",
    "texts = splitter.split_text(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I can conceive of a national destiny which meets the responsibilities of today and measures up to', 'and measures up to the possibilities of tomorrow. Behold a republic resting securely upon the', 'securely upon the mountain of eternal truth. A republic applying in practice and proclaiming to the', 'proclaiming to the world the self-evident propositions that all men are created equal, that they', 'equal, that they are endowed with inalienable rights, that governments are instituted among men to', 'among men to secure these rights, and that governments derive their just powers from the consent of', 'from the consent of the governed. Behold a republic in which civil and religious liberty stimulate', 'liberty stimulate all to earnest endeavor, and in which the law restrains every hand uplifted for a', \"hand uplifted for a neighbor's injury. A republic in which every citizen is a sovereign, but in\", 'a sovereign, but in which no one cares to wear a crown. Behold a republic standing erect while', 'erect while empires all around or bow beneath the weight of their own armaments. A republic whose', 'A republic whose flag is love while other flags are only fears. Behold a republic increasing in', 'increasing in population, in wealth, in strength, and in influence, solving the problems of', 'the problems of civilization and facing the coming of a universal brotherhood. A republic which', 'A republic which shakes, throes, and dissolves aristocracies by its silent example and gives light', 'and gives light and inspiration to those who sit in darkness. Behold a republic gradually but', \"gradually but surely becoming a supreme moral factor in the world's progress and the accepted\", \"and the accepted arbiter of the world's dispute. A republic whose history, like the path of the\", 'the path of the just, is as the shining light that shineth more and more unto the perfect day.']\n",
      "\n",
      "The length of the texts is 19\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the texts, notice how there is a bit of overlap between them\n",
    "print(texts)\n",
    "\n",
    "# So that we know how many texts we have:\n",
    "print(f\"\\nThe length of the texts is {len(texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the embeddings \n",
    "\n",
    "embeddings = OllamaEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add Text to the Vectorstore**\n",
    "\n",
    "Here, I use FAISS as the vectorstore. Faiss is a library for efficient similarity search and clustering of dense vectors. You can also use alternatives like Pinecone, Qdrant, or Chroma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vector store using the texts and embeddings and put it in a vector database\n",
    "\n",
    "docsearch = FAISS.from_texts(texts, embeddings, metadatas=[{\"source\": str(i)} for i in range(len(texts))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the LLM Model & Prompt our LLM using Context from the Chroma Vectorstore**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the local LLM Model we will use\n",
    "llm = Ollama(model='llama2', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the Prompt**\n",
    "\n",
    "We'll use a QA chain (this is a chain for performing question-answering tasks with a retrieval component) - since we'd like to ask questions and get answers and continue asking questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import chatprompttemplate \n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RAG prompt\n",
    "rag_prompt = ChatPromptTemplate(\n",
    "    input_variables=['context', 'question'], \n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=['context', 'question'], \n",
    "                template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. \n",
    "                If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "                \\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\"\"\n",
    "                )\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "# Chain\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=rag_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set a Query**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query\n",
    "query = \"What is the idea of the republic?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find similar documents to the search query \n",
    "docs = docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='among men to secure these rights, and that governments derive their just powers from the consent of', metadata={'source': '5'}),\n",
       " Document(page_content='proclaiming to the world the self-evident propositions that all men are created equal, that they', metadata={'source': '3'}),\n",
       " Document(page_content='I can conceive of a national destiny which meets the responsibilities of today and measures up to', metadata={'source': '0'}),\n",
       " Document(page_content='increasing in population, in wealth, in strength, and in influence, solving the problems of', metadata={'source': '12'})]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the docs determined to be semantically similar to the query\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate a Response Using a Chain Completion Request**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a response variable to the output of the chain\n",
    "response = chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display the response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the context provided, the idea of the republic is to establish a system of government where power is held by the people, rather than by a monarch or elite group. The Declaration of Independence proclaims that governments derive their just powers from the consent of the governed, and that all men are created equal with inherent rights to life, liberty, and the pursuit of happiness. This idea is central to the concept of democracy and the notion of self-government, where citizens have a voice in how they are governed and can participate in shaping their country's destiny.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"output_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the LLM to evaluate the response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Approach: Abandoning 'Trad' RAG\n",
    "\n",
    "#### Skip the Embeddings & Vectorstore and Place Entire Transcription into LLM Completion Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this test, I will dismiss the standard RAG approach with it's embeddings and vectorstore, and instead place the entire transcription into the LLM Completion Request. This will allow us to see how the LLM performs without the vectorstore and embeddings.\n",
    "\n",
    "Note, this approach will not work for all use cases, as often transcriptions can be very long. However, considering that we have a short one to play with, it should be enough for some initial tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
